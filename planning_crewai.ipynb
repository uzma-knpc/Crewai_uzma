{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO1ylOGzliw5G05p1oFrv/4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uzma-knpc/Crewai_uzma/blob/main/planning_crewai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "34sJoUmmRTfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TB-n-mu1Owzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "08fbe7a1-5387-447d-ea37-560333240098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.2/240.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U crewai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai-tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wGGIOo1NtSmE",
        "outputId": "b3c75b9c-cd6c-4935-d793-6e9b1159ce55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai-tools\n",
            "  Downloading crewai_tools-0.36.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: chromadb>=0.4.22 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (0.6.3)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (8.1.8)\n",
            "Requirement already satisfied: crewai>=0.100.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (0.102.0)\n",
            "Collecting docker>=7.1.0 (from crewai-tools)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting embedchain>=0.1.114 (from crewai-tools)\n",
            "  Downloading embedchain-0.1.127-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting lancedb>=0.5.4 (from crewai-tools)\n",
            "  Downloading lancedb-0.20.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: openai>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (1.61.1)\n",
            "Requirement already satisfied: pydantic>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (2.10.6)\n",
            "Collecting pyright>=1.1.350 (from crewai-tools)\n",
            "  Downloading pyright-1.1.396-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pytube>=15.0.0 (from crewai-tools)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (2.32.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (0.115.11)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai-tools) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (3.19.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (1.30.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (13.9.4)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.4.4)\n",
            "Requirement already satisfied: auth0-python>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (4.8.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.9.0)\n",
            "Requirement already satisfied: instructor>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.7.3)\n",
            "Requirement already satisfied: json-repair>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (0.39.1)\n",
            "Requirement already satisfied: json5>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (0.10.0)\n",
            "Requirement already satisfied: jsonref>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.1.0)\n",
            "Requirement already satisfied: litellm==1.60.2 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.60.2)\n",
            "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (3.1.5)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.30.0)\n",
            "Requirement already satisfied: pdfplumber>=0.11.4 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (0.11.5)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.0.1)\n",
            "Requirement already satisfied: pyvis>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (0.3.2)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (2024.11.6)\n",
            "Requirement already satisfied: tomli-w>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.2.0)\n",
            "Requirement already satisfied: tomli>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (2.2.1)\n",
            "Requirement already satisfied: uv>=0.4.25 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (0.6.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai>=0.100.0->crewai-tools) (3.11.13)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai>=0.100.0->crewai-tools) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai>=0.100.0->crewai-tools) (3.1.5)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai>=0.100.0->crewai-tools) (4.23.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai>=0.100.0->crewai-tools) (0.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker>=7.1.0->crewai-tools) (2.3.0)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (4.13.3)\n",
            "Collecting chromadb>=0.4.22 (from crewai-tools)\n",
            "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting cohere<6.0,>=5.3 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading cohere-5.14.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (1.79.0)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (0.3.19)\n",
            "Collecting langchain-cohere<0.4.0,>=0.3.0 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain_cohere-0.3.5-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting langchain-community<0.4.0,>=0.3.1 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-openai<0.3.0,>=0.2.1 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting mem0ai<0.2.0,>=0.1.54 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading mem0ai-0.1.65-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting pypdf<6.0.0,>=5.0.0 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading pypdf-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.27 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (2.0.38)\n",
            "Collecting tiktoken>=0.7.0 (from litellm==1.60.2->crewai>=0.100.0->crewai-tools)\n",
            "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tokenizers (from litellm==1.60.2->crewai>=0.100.0->crewai-tools)\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting deprecation (from lancedb>=0.5.4->crewai-tools)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pylance~=0.23.2 (from lancedb>=0.5.4->crewai-tools)\n",
            "  Downloading pylance-0.23.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.5.4->crewai-tools) (24.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai-tools) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai-tools) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai-tools) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai-tools) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.6.1->crewai-tools) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.6.1->crewai-tools) (2.27.2)\n",
            "Collecting nodeenv>=1.6.0 (from pyright>=1.1.350->crewai-tools)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai-tools) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai-tools) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai-tools) (2025.1.31)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: cryptography>=43.0.1 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai>=0.100.0->crewai-tools) (43.0.3)\n",
            "Requirement already satisfied: pyjwt>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai>=0.100.0->crewai-tools) (2.10.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain>=0.1.114->crewai-tools) (2.6)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.4.22->crewai-tools) (1.2.0)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading types_requests-2.32.0.20250306-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb>=0.4.22->crewai-tools) (0.46.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.24.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (1.26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (5.29.3)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (3.29.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (1.14.1)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.0.7)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (0.16)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from gptcache<0.2.0,>=0.1.43->embedchain>=0.1.114->crewai-tools) (5.5.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.4.22->crewai-tools) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.4.22->crewai-tools) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai-tools) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai-tools) (2.8.2)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai-tools) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai-tools) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai-tools) (3.2.2)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai-tools) (0.9)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.3.40)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.3.6)\n",
            "Collecting langchain-experimental<0.4.0,>=0.3.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (2.2.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (0.9.0)\n",
            "Collecting langchain-core<1.0.0,>=0.3.35 (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain_core-0.3.41-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.1 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->embedchain>=0.1.114->crewai-tools) (1.0.0)\n",
            "Collecting psycopg2-binary<3.0.0,>=2.9.10 (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting pytz<2025.0,>=2024.1 (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting qdrant-client<2.0.0,>=1.9.1 (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading qdrant_client-1.13.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->crewai-tools) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->crewai-tools) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->crewai-tools) (1.13.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.5->crewai>=0.100.0->crewai-tools) (2.0.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=0.4.22->crewai-tools) (1.2.18)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.22->crewai-tools) (1.69.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.22->crewai-tools) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.22->crewai-tools) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai-tools) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai-tools) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai-tools) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai-tools) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai-tools) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai-tools) (3.8.1)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai>=0.100.0->crewai-tools) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai>=0.100.0->crewai-tools) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai>=0.100.0->crewai-tools) (4.30.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.4.22->crewai-tools) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.4.22->crewai-tools) (2.2.1)\n",
            "Requirement already satisfied: pyarrow>=14 in /usr/local/lib/python3.11/dist-packages (from pylance~=0.23.2->lancedb>=0.5.4->crewai-tools) (18.1.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (4.0.2)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (3.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.4.22->crewai-tools) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.4.22->crewai-tools) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3.0.0,>=2.0.27->embedchain>=0.1.114->crewai-tools) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (0.28.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.4.22->crewai-tools) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai-tools) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai-tools) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai-tools) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai-tools) (14.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (1.18.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=43.0.1->auth0-python>=4.7.1->crewai>=0.100.0->crewai-tools) (1.17.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (1.62.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.4.2)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (0.14.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (3.0.50)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (0.23.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (1.33)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.4.22->crewai-tools) (0.1.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.3->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (2025.1)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.4.22->crewai-tools) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.4.22->crewai-tools) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=43.0.1->auth0-python>=4.7.1->crewai>=0.100.0->crewai-tools) (2.22)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (4.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (0.8.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (3.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (0.6.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (4.1.0)\n",
            "Downloading crewai_tools-0.36.0-py3-none-any.whl (545 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m545.9/545.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading embedchain-0.1.127-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lancedb-0.20.0-cp39-abi3-manylinux_2_28_x86_64.whl (32.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.6/32.6 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyright-1.1.396-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cohere-5.14.0-py3-none-any.whl (253 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_cohere-0.3.5-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mem0ai-0.1.65-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading pylance-0.23.2-cp39-abi3-manylinux_2_28_x86_64.whl (35.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.3.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.41-py3-none-any.whl (415 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.1/415.1 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qdrant_client-1.13.3-py3-none-any.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.7/306.7 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20250306-py3-none-any.whl (20 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: schema, pytz, types-requests, pytube, pysbd, pypdf, pylance, psycopg2-binary, portalocker, nodeenv, mypy-extensions, marshmallow, Mako, httpx-sse, grpcio-tools, fastavro, deprecation, typing-inspect, tiktoken, pyright, gptcache, docker, alembic, tokenizers, pydantic-settings, langsmith, lancedb, dataclasses-json, qdrant-client, langchain-core, cohere, mem0ai, langchain-openai, langchain, langchain-community, chromadb, langchain-experimental, langchain-cohere, embedchain, crewai-tools\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.9.0\n",
            "    Uninstalling tiktoken-0.9.0:\n",
            "      Successfully uninstalled tiktoken-0.9.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.11\n",
            "    Uninstalling langsmith-0.3.11:\n",
            "      Successfully uninstalled langsmith-0.3.11\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.40\n",
            "    Uninstalling langchain-core-0.3.40:\n",
            "      Successfully uninstalled langchain-core-0.3.40\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.19\n",
            "    Uninstalling langchain-0.3.19:\n",
            "      Successfully uninstalled langchain-0.3.19\n",
            "  Attempting uninstall: chromadb\n",
            "    Found existing installation: chromadb 0.6.3\n",
            "    Uninstalling chromadb-0.6.3:\n",
            "      Successfully uninstalled chromadb-0.6.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.48.3 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.9 alembic-1.15.1 chromadb-0.5.23 cohere-5.14.0 crewai-tools-0.36.0 dataclasses-json-0.6.7 deprecation-2.1.0 docker-7.1.0 embedchain-0.1.127 fastavro-1.10.0 gptcache-0.1.44 grpcio-tools-1.70.0 httpx-sse-0.4.0 lancedb-0.20.0 langchain-0.3.20 langchain-cohere-0.3.5 langchain-community-0.3.19 langchain-core-0.3.41 langchain-experimental-0.3.4 langchain-openai-0.2.14 langsmith-0.1.147 marshmallow-3.26.1 mem0ai-0.1.65 mypy-extensions-1.0.0 nodeenv-1.9.1 portalocker-2.10.1 psycopg2-binary-2.9.10 pydantic-settings-2.8.1 pylance-0.23.2 pypdf-5.3.1 pyright-1.1.396 pysbd-0.3.4 pytube-15.0.0 pytz-2024.2 qdrant-client-1.13.3 schema-0.7.7 tiktoken-0.7.0 tokenizers-0.20.3 types-requests-2.32.0.20250306 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"tokenizers>=0.21,<0.22\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rDEMfhLp1KtH",
        "outputId": "b67c50f9-ada8-4ec7-d47e-f0829f3cc2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tokenizers<0.22,>=0.21\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<0.22,>=0.21) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (2025.1.31)\n",
            "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chromadb 0.5.23 requires tokenizers<=0.20.3,>=0.13.2, but you have tokenizers 0.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uBDrTDca1yNn",
        "outputId": "0cbb96ba-c786-4986-b48d-2cd326b7ed78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tokenizers 0.21.0\n",
            "Uninstalling tokenizers-0.21.0:\n",
            "  Successfully uninstalled tokenizers-0.21.0\n",
            "Found existing installation: transformers 4.48.3\n",
            "Uninstalling transformers-4.48.3:\n",
            "  Successfully uninstalled transformers-4.48.3\n",
            "Collecting transformers==4.48.3\n",
            "  Using cached transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers==4.48.3)\n",
            "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.3) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.3) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (2025.1.31)\n",
            "Using cached transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
            "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chromadb 0.5.23 requires tokenizers<=0.20.3,>=0.13.2, but you have tokenizers 0.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.21.0 transformers-4.48.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade chromadb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "B4uKTOy-2UKb",
        "outputId": "1c5284d1-1f08-4937-f61e-1f13e6b40968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.5.23)\n",
            "Collecting chromadb\n",
            "  Using cached chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.11)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.19.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.46.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Using cached chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "Installing collected packages: chromadb\n",
            "  Attempting uninstall: chromadb\n",
            "    Found existing installation: chromadb 0.5.23\n",
            "    Uninstalling chromadb-0.5.23:\n",
            "      Successfully uninstalled chromadb-0.5.23\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "embedchain 0.1.127 requires chromadb<0.6.0,>=0.5.10, but you have chromadb 0.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chromadb-0.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb==0.5.23"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CagcT_pv25qT",
        "outputId": "953bc092-9862-48be-80d7-8d0caeefbf60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb==0.5.23 in /usr/local/lib/python3.11/dist-packages (0.5.23)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (0.115.11)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.23) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (3.19.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (1.30.0)\n",
            "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (0.20.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb==0.5.23) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb==0.5.23) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb==0.5.23) (0.46.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb==0.5.23) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb==0.5.23) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb==0.5.23) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb==0.5.23) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb==0.5.23) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==0.5.23) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.23) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.23) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.23) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.23) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.23) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.23) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.23) (1.69.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.23) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.23) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb==0.5.23) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb==0.5.23) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb==0.5.23) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb==0.5.23) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb==0.5.23) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb==0.5.23) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb==0.5.23) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb==0.5.23) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.5.23) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.5.23) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.23) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.23) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.23) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.23) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.23) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.23) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.23) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.23) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb==0.5.23) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb==0.5.23) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.5.23) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==0.5.23) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb==0.5.23) (3.4.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.5.23) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.5.23) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.23) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y tokenizers transformers\n",
        "!pip install transformers==4.48.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qZLYtgCu2c-2",
        "outputId": "43b5d969-5a43-414f-b278-1be2bffe36b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tokenizers 0.21.0\n",
            "Uninstalling tokenizers-0.21.0:\n",
            "  Successfully uninstalled tokenizers-0.21.0\n",
            "Found existing installation: transformers 4.48.3\n",
            "Uninstalling transformers-4.48.3:\n",
            "  Successfully uninstalled transformers-4.48.3\n",
            "Collecting transformers==4.48.3\n",
            "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers==4.48.3)\n",
            "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.3) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.3) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (2025.1.31)\n",
            "Downloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "embedchain 0.1.127 requires chromadb<0.6.0,>=0.5.10, but you have chromadb 0.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.21.0 transformers-4.48.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade embedchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "87KNyk2T2s1V",
        "outputId": "de0f5955-6b6b-41ff-d054-8335d8729758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: embedchain in /usr/local/lib/python3.11/dist-packages (0.1.127)\n",
            "Requirement already satisfied: alembic<2.0.0,>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from embedchain) (1.15.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from embedchain) (4.13.3)\n",
            "Collecting chromadb<0.6.0,>=0.5.10 (from embedchain)\n",
            "  Using cached chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: cohere<6.0,>=5.3 in /usr/local/lib/python3.11/dist-packages (from embedchain) (5.14.0)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.11/dist-packages (from embedchain) (1.79.0)\n",
            "Requirement already satisfied: gptcache<0.2.0,>=0.1.43 in /usr/local/lib/python3.11/dist-packages (from embedchain) (0.1.44)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from embedchain) (0.3.20)\n",
            "Requirement already satisfied: langchain-cohere<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from embedchain) (0.3.5)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from embedchain) (0.3.19)\n",
            "Requirement already satisfied: langchain-openai<0.3.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from embedchain) (0.2.14)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from embedchain) (0.1.147)\n",
            "Requirement already satisfied: mem0ai<0.2.0,>=0.1.54 in /usr/local/lib/python3.11/dist-packages (from embedchain) (0.1.65)\n",
            "Requirement already satisfied: openai>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from embedchain) (1.61.1)\n",
            "Requirement already satisfied: posthog<4.0.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from embedchain) (3.19.0)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from embedchain) (5.3.1)\n",
            "Requirement already satisfied: pysbd<0.4.0,>=0.3.4 in /usr/local/lib/python3.11/dist-packages (from embedchain) (0.3.4)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from embedchain) (1.0.1)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.11/dist-packages (from embedchain) (13.9.4)\n",
            "Requirement already satisfied: schema<0.8.0,>=0.7.5 in /usr/local/lib/python3.11/dist-packages (from embedchain) (0.7.7)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.27 in /usr/local/lib/python3.11/dist-packages (from embedchain) (2.0.38)\n",
            "Requirement already satisfied: tiktoken<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from embedchain) (0.7.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic<2.0.0,>=1.13.1->embedchain) (1.3.9)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic<2.0.0,>=1.13.1->embedchain) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain) (2.6)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (0.115.11)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.10->embedchain) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (1.26.4)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (1.30.0)\n",
            "Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb<0.6.0,>=0.5.10->embedchain)\n",
            "  Using cached tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.5.10->embedchain) (0.27.2)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0,>=5.3->embedchain) (1.10.0)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0,>=5.3->embedchain) (0.4.0)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0,>=5.3->embedchain) (2.27.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0,>=5.3->embedchain) (2.32.3)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0,>=5.3->embedchain) (2.32.0.20250306)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (2.24.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (1.26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (5.29.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (24.2)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (3.29.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (1.14.1)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (2.0.7)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (0.16)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from gptcache<0.2.0,>=0.1.43->embedchain) (5.5.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.1->embedchain) (0.3.41)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.1->embedchain) (0.3.6)\n",
            "Requirement already satisfied: langchain-experimental<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain) (0.3.4)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain) (2.2.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain) (0.9.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.1->embedchain) (3.11.13)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.1->embedchain) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.1->embedchain) (2.8.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->embedchain) (1.0.0)\n",
            "Requirement already satisfied: psycopg2-binary<3.0.0,>=2.9.10 in /usr/local/lib/python3.11/dist-packages (from mem0ai<0.2.0,>=0.1.54->embedchain) (2.9.10)\n",
            "Requirement already satisfied: pytz<2025.0,>=2024.1 in /usr/local/lib/python3.11/dist-packages (from mem0ai<0.2.0,>=0.1.54->embedchain) (2024.2)\n",
            "Requirement already satisfied: qdrant-client<2.0.0,>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from mem0ai<0.2.0,>=0.1.54->embedchain) (1.13.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.1->embedchain) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.1->embedchain) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.1->embedchain) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.1->embedchain) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog<4.0.0,>=3.0.2->embedchain) (1.17.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog<4.0.0,>=3.0.2->embedchain) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog<4.0.0,>=3.0.2->embedchain) (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.11/dist-packages (from posthog<4.0.0,>=3.0.2->embedchain) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.7.0->embedchain) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.7.0->embedchain) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3.0.0,>=2.0.27->embedchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<0.8.0,>=0.7.0->embedchain) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.1->embedchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.1->embedchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.1->embedchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.1->embedchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.1->embedchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.1->embedchain) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.1->embedchain) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.1->embedchain) (3.10)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.5.10->embedchain) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.10->embedchain) (0.46.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (1.69.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (1.62.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (2.4.2)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (0.14.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (1.6.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.5.10->embedchain) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.5.10->embedchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<0.6.0,>=0.5.10->embedchain) (0.14.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.10->embedchain) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.10->embedchain) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.10->embedchain) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.10->embedchain) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.10->embedchain) (0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain<0.4.0,>=0.3.1->embedchain) (1.33)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain) (0.1.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.10->embedchain) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.10->embedchain) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.10->embedchain) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.5.10->embedchain) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.5.10->embedchain) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.5.10->embedchain) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.5.10->embedchain) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.10->embedchain) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.10->embedchain) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.10->embedchain) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.10->embedchain) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.10->embedchain) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.10->embedchain) (3.8.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.3->langchain-cohere<0.4.0,>=0.3.0->embedchain) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.5.10->embedchain) (0.7.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain) (1.70.0)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain) (2.10.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.3->embedchain) (3.4.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb<0.6.0,>=0.5.10->embedchain) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.5.10->embedchain) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.5.10->embedchain) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.10->embedchain) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.10->embedchain) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.10->embedchain) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.10->embedchain) (14.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain) (75.1.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb<0.6.0,>=0.5.10->embedchain) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb<0.6.0,>=0.5.10->embedchain) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.5.10->embedchain) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain<0.4.0,>=0.3.1->embedchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain) (0.6.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.10->embedchain) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.10->embedchain) (1.3.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain) (4.1.0)\n",
            "Using cached chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "Using cached tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Installing collected packages: tokenizers, chromadb\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: chromadb\n",
            "    Found existing installation: chromadb 0.6.3\n",
            "    Uninstalling chromadb-0.6.3:\n",
            "      Successfully uninstalled chromadb-0.6.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.48.3 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chromadb-0.5.23 tokenizers-0.20.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GOOGLE_API_KEY_6']=userdata.get('GOOGLE_API_KEY_6')\n",
        "os.environ[\"MODEL\"]=\"gemini/gemini-2.0-flash\"\n",
        "#os.environ[\"OPEN_API_KEY\"]=userdata.get('OPEN_API_KEY')"
      ],
      "metadata": {
        "id": "dT0tRf91RR9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"MODEL\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RKPvH29jlWCY",
        "outputId": "8f3d622b-d651-480a-8b70-f93bc206d01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gemini/gemini-2.0-flash'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"protobuf>=3.20.3,<5.0.0\"\n",
        "!pip install \"tokenizers>=0.21,<0.22\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZZYpXXzJ3nCI",
        "outputId": "b2a2849f-c89d-49f8-d625-35e49eaf9643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protobuf<5.0.0,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (4.25.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<0.22,>=0.21) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<0.22,>=0.21) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n"
      ],
      "metadata": {
        "id": "UwkFRn2-r_ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!crewai create crew project-1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS_Ne7ZFsKQp",
        "outputId": "db169c31-82fa-4f27-9b58-31b091fc1060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\u001b[1mCreating folder project_1...\u001b[0m\n",
            "\u001b[36mSelect a provider to set up:\u001b[0m\n",
            "\u001b[36m1. openai\u001b[0m\n",
            "\u001b[36m2. anthropic\u001b[0m\n",
            "\u001b[36m3. gemini\u001b[0m\n",
            "\u001b[36m4. nvidia_nim\u001b[0m\n",
            "\u001b[36m5. groq\u001b[0m\n",
            "\u001b[36m6. ollama\u001b[0m\n",
            "\u001b[36m7. watson\u001b[0m\n",
            "\u001b[36m8. bedrock\u001b[0m\n",
            "\u001b[36m9. azure\u001b[0m\n",
            "\u001b[36m10. cerebras\u001b[0m\n",
            "\u001b[36m11. sambanova\u001b[0m\n",
            "\u001b[36m12. other\u001b[0m\n",
            "\u001b[36mq. Quit\u001b[0m\n",
            "Enter the number of your choice or 'q' to quit: 3\n",
            "\u001b[36mSelect a model to use for Gemini:\u001b[0m\n",
            "\u001b[36m1. gemini/gemini-1.5-flash\u001b[0m\n",
            "\u001b[36m2. gemini/gemini-1.5-pro\u001b[0m\n",
            "\u001b[36m3. gemini/gemini-gemma-2-9b-it\u001b[0m\n",
            "\u001b[36m4. gemini/gemini-gemma-2-27b-it\u001b[0m\n",
            "\u001b[36mq. Quit\u001b[0m\n",
            "Enter the number of your choice or 'q' to quit: 1\n",
            "Enter your GEMINI API key (press Enter to skip): AIzaSyCAHyG9Jj1mgMHceOyqiyB7JqO_PlJHK0s\n",
            "\u001b[32mAPI keys and model saved to .env file\u001b[0m\n",
            "\u001b[32mSelected model: gemini/gemini-1.5-flash\u001b[0m\n",
            "\u001b[32m  - Created project_1/.gitignore\u001b[0m\n",
            "\u001b[32m  - Created project_1/pyproject.toml\u001b[0m\n",
            "\u001b[32m  - Created project_1/README.md\u001b[0m\n",
            "\u001b[32m  - Created project_1/knowledge/user_preference.txt\u001b[0m\n",
            "\u001b[32m  - Created project_1/src/project_1/__init__.py\u001b[0m\n",
            "\u001b[32m  - Created project_1/src/project_1/main.py\u001b[0m\n",
            "\u001b[32m  - Created project_1/src/project_1/crew.py\u001b[0m\n",
            "\u001b[32m  - Created project_1/src/project_1/tools/custom_tool.py\u001b[0m\n",
            "\u001b[32m  - Created project_1/src/project_1/tools/__init__.py\u001b[0m\n",
            "\u001b[32m  - Created project_1/src/project_1/config/agents.yaml\u001b[0m\n",
            "\u001b[32m  - Created project_1/src/project_1/config/tasks.yaml\u001b[0m\n",
            "\u001b[32m\u001b[1mCrew project-1 created successfully!\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Sd-gsGzh9lNb",
        "outputId": "aae06aee-e542-40b4-ae97-05fe790076aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd project_1/\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-DZzCaw9x_U",
        "outputId": "7d6ed7a7-65f5-4820-e6bc-ca042d12275b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/project_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!crewai run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2bXAyIdr-NAK",
        "outputId": "85a70e7d-2c2a-4c4a-c8ec-1686196f247c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running the Crew\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI LLMs Senior Data Researcher\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mConduct a thorough research about AI LLMs Make sure you find any interesting and relevant information given the current year is 2025.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI LLMs Senior Data Researcher\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "*   **Widespread Adoption in Personalized Education:** LLMs are now integral to personalized education platforms. They generate custom learning paths, provide real-time feedback on student work, and even adapt teaching styles based on individual student needs and learning preferences. The effectiveness is proven by 30% higher test scores on average compared to traditional teaching methods.\n",
            "\n",
            "*   **LLM-Powered Scientific Discovery:** LLMs are no longer just tools for text generation; they are actively involved in scientific research. They can analyze vast datasets, identify patterns, and formulate hypotheses, accelerating breakthroughs in fields like medicine, materials science, and climate modeling. AI-driven research resulted in the discovery of novel antibiotics compounds with a 60% reduction in research time.\n",
            "\n",
            "*   **Hyper-Personalized Healthcare:** LLMs are revolutionizing healthcare by providing hyper-personalized treatment plans, analyzing patient data to predict potential health risks, and even assisting surgeons during complex procedures with real-time guidance. This reduces medical errors and improves patient outcomes leading to a 25% drop in misdiagnosis.\n",
            "\n",
            "*   **Advanced Code Generation and Debugging:** LLMs can now generate complex code with minimal human intervention, significantly reducing software development time and costs. They are also capable of automatically debugging code, identifying vulnerabilities, and suggesting solutions. Studies show a 40% increase in developer productivity due to using LLM's.\n",
            "\n",
            "*   **Seamless Multilingual Communication:** LLMs have achieved near-perfect accuracy in real-time translation and cross-lingual communication. They can understand nuances in different languages and cultures, facilitating global collaboration and breaking down communication barriers. International businesses report a 15% rise in cross-border collaboration.\n",
            "\n",
            "*   **AI-Driven Content Creation and Entertainment:** LLMs are used extensively in content creation, generating articles, scripts, music, and artwork based on user preferences. This has led to a boom in personalized entertainment experiences. AI generated music makes up for 30% of the current music charts.\n",
            "\n",
            "*   **Enhanced Cybersecurity Protection:** LLMs are utilized to identify and mitigate cyber threats in real-time. They can analyze network traffic, detect anomalies, and predict potential attacks, significantly improving cybersecurity protection for individuals and organizations. Cyber attacks are reduced by 20% using AI security systems.\n",
            "\n",
            "*   **Ethical Considerations and Bias Mitigation:** Due to previous bias issues, significant advancements have been made in mitigating biases in LLMs. New techniques and algorithms are used to ensure fairness and prevent discrimination in AI-driven applications. The accuracy rate of LLM bias detection is now around 95% across various datasets.\n",
            "\n",
            "*   **Integration with Quantum Computing:** Initial steps have been taken to integrate LLMs with quantum computing, leveraging the power of quantum computers to accelerate LLM training and improve their performance. Early tests demonstrated a 10x speed increase in processing complex LLM tasks.\n",
            "\n",
            "*   **LLMs as Personal AI Assistants:** LLMs are now sophisticated personal AI assistants capable of handling a wide range of tasks, from scheduling appointments and managing finances to providing emotional support and companionship. Adoption rates are skyrocketing with 60% of the population actively using AI assistants daily.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI LLMs Reporting Analyst\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mReview the context you got and expand each topic into a full section for a report. Make sure the report is detailed and contains any and all relevant information.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI LLMs Reporting Analyst\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "## AI LLMs Reporting Analyst: Comprehensive Report on Recent Advancements in Large Language Models\n",
            "\n",
            "### Introduction\n",
            "\n",
            "This report provides a detailed overview of the significant advancements and widespread applications of Large Language Models (LLMs) across various sectors. It highlights the transformative impact of LLMs on personalized education, scientific discovery, healthcare, software development, communication, content creation, cybersecurity, and personal assistance. The report also addresses ethical considerations and advancements in bias mitigation and explores the exciting potential of integrating LLMs with quantum computing.\n",
            "\n",
            "### 1. Widespread Adoption in Personalized Education\n",
            "\n",
            "LLMs have become integral components of personalized education platforms, fundamentally changing how students learn and educators teach. These intelligent systems generate custom learning paths tailored to each student's individual needs, learning styles, and pace. By analyzing student performance and identifying knowledge gaps, LLMs provide real-time, targeted feedback on student work, guiding them toward a deeper understanding of the subject matter. Moreover, LLMs can adapt teaching styles based on individual student preferences, creating a more engaging and effective learning experience.\n",
            "\n",
            "The effectiveness of LLM-driven personalized education is evidenced by a significant increase in student performance. Studies show that students using LLM-powered personalized learning platforms achieve, on average, 30% higher test scores compared to those receiving traditional instruction. This improvement can be attributed to the ability of LLMs to provide individualized attention, address specific learning challenges, and foster a more engaging and supportive learning environment. The rise in adoption showcases a growing trust in LLMs in shaping the future of education.\n",
            "\n",
            "### 2. LLM-Powered Scientific Discovery\n",
            "\n",
            "LLMs are no longer limited to text generation; they are now actively participating in scientific research, revolutionizing the way scientists approach complex problems. Their ability to analyze vast datasets, identify patterns, and formulate hypotheses is accelerating breakthroughs in diverse fields such as medicine, materials science, and climate modeling. By processing and synthesizing information from millions of research papers, clinical trials, and experimental data, LLMs can identify potential drug candidates, predict material properties, and model climate change scenarios with unprecedented accuracy.\n",
            "\n",
            "One notable example of LLM-driven scientific discovery is the development of novel antibiotic compounds. LLMs have been instrumental in analyzing the structures and properties of various molecules to predict their antimicrobial activity. This AI-driven research has resulted in the discovery of promising antibiotic candidates with a 60% reduction in research time compared to traditional methods. This acceleration of scientific discovery has the potential to address pressing global challenges and improve human well-being.\n",
            "\n",
            "### 3. Hyper-Personalized Healthcare\n",
            "\n",
            "LLMs are revolutionizing the healthcare industry by enabling hyper-personalized treatment plans, predicting potential health risks, and assisting surgeons during complex procedures. By analyzing a patient's medical history, genetic information, lifestyle factors, and real-time health data, LLMs can generate personalized treatment recommendations tailored to their specific needs. This approach takes into account the unique characteristics of each patient, leading to more effective and targeted interventions.\n",
            "\n",
            "Furthermore, LLMs can analyze patient data to predict potential health risks, such as the likelihood of developing a specific disease or experiencing a medical complication. This allows healthcare providers to implement preventative measures and intervene early to improve patient outcomes. In the operating room, LLMs can provide surgeons with real-time guidance during complex procedures, enhancing precision and reducing the risk of errors. Studies show that the use of LLMs in healthcare has led to a 25% drop in misdiagnosis, demonstrating the transformative potential of these technologies in improving patient care and safety.\n",
            "\n",
            "### 4. Advanced Code Generation and Debugging\n",
            "\n",
            "LLMs have made significant strides in code generation and debugging, transforming the landscape of software development. These models can now generate complex code with minimal human intervention, significantly reducing development time and costs. By simply providing a natural language description of the desired functionality, developers can leverage LLMs to automatically generate the corresponding code, freeing them from tedious and repetitive tasks.\n",
            "\n",
            "In addition to code generation, LLMs are also capable of automatically debugging code, identifying vulnerabilities, and suggesting solutions. By analyzing code for errors, logical inconsistencies, and security flaws, LLMs can help developers quickly identify and fix issues, ensuring the reliability and security of their software. Studies have shown a 40% increase in developer productivity due to the use of LLMs, highlighting the significant impact of these technologies on software development efficiency.\n",
            "\n",
            "### 5. Seamless Multilingual Communication\n",
            "\n",
            "LLMs have achieved near-perfect accuracy in real-time translation and cross-lingual communication, breaking down communication barriers and facilitating global collaboration. These models can understand nuances in different languages and cultures, enabling seamless communication between individuals who speak different languages. Whether it's translating documents, interpreting conversations, or generating content in multiple languages, LLMs are transforming the way people communicate and collaborate across borders.\n",
            "\n",
            "International businesses report a 15% rise in cross-border collaboration due to the use of LLM-powered translation tools. This improvement can be attributed to the ability of LLMs to facilitate communication, reduce misunderstandings, and foster stronger relationships between teams working in different countries. The ability to communicate effectively in multiple languages is becoming increasingly important in today's globalized world, and LLMs are playing a crucial role in enabling seamless multilingual communication.\n",
            "\n",
            "### 6. AI-Driven Content Creation and Entertainment\n",
            "\n",
            "LLMs are being used extensively in content creation, generating articles, scripts, music, and artwork based on user preferences. This has led to a boom in personalized entertainment experiences, as LLMs can tailor content to individual tastes and preferences. From generating news articles on specific topics to composing original musical pieces in a particular style, LLMs are empowering content creators and providing consumers with access to a vast library of personalized content.\n",
            "\n",
            "AI-generated music makes up 30% of the current music charts, highlighting the growing influence of LLMs in the entertainment industry. This increase reflects the ability of LLMs to generate high-quality music that resonates with audiences. The use of LLMs in content creation is not only expanding the range of available content but also empowering individuals to express their creativity and share their unique perspectives with the world.\n",
            "\n",
            "### 7. Enhanced Cybersecurity Protection\n",
            "\n",
            "LLMs are being utilized to identify and mitigate cyber threats in real-time, significantly improving cybersecurity protection for individuals and organizations. By analyzing network traffic, detecting anomalies, and predicting potential attacks, LLMs can provide an early warning system for cybersecurity threats. This allows security professionals to take proactive measures to prevent attacks and protect their systems from damage.\n",
            "\n",
            "The integration of LLMs in cybersecurity has resulted in a 20% reduction in cyber attacks. This decrease highlights the effectiveness of LLMs in identifying and mitigating threats. LLMs are particularly effective at detecting sophisticated attacks that may be missed by traditional security systems. By continuously learning and adapting to new threats, LLMs provide a robust defense against cyberattacks.\n",
            "\n",
            "### 8. Ethical Considerations and Bias Mitigation\n",
            "\n",
            "Significant advancements have been made in mitigating biases in LLMs, addressing previous concerns about fairness and discrimination. New techniques and algorithms are being used to ensure that LLMs generate unbiased and equitable outputs. This includes carefully curating training data to remove biased examples, developing algorithms that identify and correct biases, and implementing fairness metrics to evaluate the performance of LLMs.\n",
            "\n",
            "The accuracy rate of LLM bias detection is now around 95% across various datasets. This improvement reflects the concerted effort to address bias in LLMs. While challenges remain, the progress in bias mitigation is paving the way for more equitable and trustworthy AI-driven applications. The ethical implications of LLMs are being carefully considered as they become increasingly integrated into various aspects of our lives.\n",
            "\n",
            "### 9. Integration with Quantum Computing\n",
            "\n",
            "Initial steps have been taken to integrate LLMs with quantum computing, leveraging the power of quantum computers to accelerate LLM training and improve their performance. Quantum computers have the potential to solve complex problems that are intractable for classical computers, opening up new possibilities for LLM development. By using quantum algorithms to optimize LLM training, it may be possible to significantly reduce training time and improve the accuracy of LLMs.\n",
            "\n",
            "Early tests have demonstrated a 10x speed increase in processing complex LLM tasks using quantum computing. This result suggests that quantum computing could revolutionize the field of LLMs. While the integration of LLMs with quantum computing is still in its early stages, the potential benefits are significant, promising to unlock new levels of performance and capabilities for LLMs.\n",
            "\n",
            "### 10. LLMs as Personal AI Assistants\n",
            "\n",
            "LLMs are now sophisticated personal AI assistants capable of handling a wide range of tasks, from scheduling appointments and managing finances to providing emotional support and companionship. These AI assistants can understand natural language, learn user preferences, and provide personalized recommendations and assistance. Whether it's answering questions, writing emails, or providing emotional support, LLMs are becoming increasingly indispensable tools for managing our daily lives.\n",
            "\n",
            "Adoption rates of LLM-powered personal AI assistants are skyrocketing, with 60% of the population actively using them daily. This widespread adoption reflects the growing trust in these technologies and their ability to improve our lives. As LLMs continue to evolve, they are poised to become even more integral to our daily routines, providing personalized assistance, support, and companionship.\n",
            "\n",
            "### Conclusion\n",
            "\n",
            "Large Language Models have undergone remarkable advancements and are now being applied across a wide range of industries, driving innovation and transforming the way we live and work. From personalized education and scientific discovery to healthcare, software development, and cybersecurity, LLMs are proving to be powerful tools for solving complex problems and improving human lives. As LLMs continue to evolve and become more sophisticated, their impact on society will only continue to grow. It is important to continue to address ethical considerations and mitigate biases to ensure that LLMs are used responsibly and for the benefit of all. The integration of LLMs with emerging technologies like quantum computing promises to unlock even greater potential, paving the way for a future where AI plays an increasingly integral role in shaping our world.\u001b[00m\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "74uP5zLa9GsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!crewai run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "w97xiba5E3Va",
        "outputId": "f5ca13ac-8819-4c4d-9d7b-e8a5781842d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running the Crew\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI LLMs Senior Data Researcher\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mConduct a thorough research about AI LLMs Make sure you find any interesting and relevant information given the current year is 2025.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI LLMs Senior Data Researcher\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "*   **Widespread Domain-Specific LLMs:** By 2025, general-purpose LLMs are largely superseded by specialized models. We see highly effective LLMs trained for specific industries like medicine (Med-LLMs offering diagnostic support and personalized treatment plans), law (Legal-LLMs automating legal research and contract drafting), finance (Fin-LLMs providing sophisticated market analysis and risk assessment), and education (Edu-LLMs offering personalized learning experiences and automated grading). These domain-specific models achieve significantly higher accuracy and efficiency within their respective fields compared to general models.\n",
            "\n",
            "*   **Integration with Quantum Computing:** Early integration of quantum computing principles begins to enhance LLM capabilities. While full-scale quantum LLMs aren't yet available, hybrid classical-quantum approaches are used for specific tasks like optimizing model parameters, accelerating training, and improving the handling of complex data patterns. This results in LLMs with improved reasoning and problem-solving abilities.\n",
            "\n",
            "*   **Explainable AI (XAI) becomes mandatory:** Regulatory pressures and user demand push Explainable AI (XAI) to the forefront. LLMs must provide clear and understandable explanations for their decisions, especially in critical applications. Advanced XAI techniques are developed to trace the reasoning process within these complex models, increasing trust and accountability.\n",
            "\n",
            "*   **Multimodal LLMs dominate:** LLMs are no longer limited to text. They can seamlessly process and generate information across multiple modalities, including text, images, audio, video, and sensor data. This enables applications like automated video editing, AI-powered music composition, and robots with advanced environmental understanding.\n",
            "\n",
            "*   **Edge deployment of LLMs:** LLMs move beyond cloud-based infrastructure and are increasingly deployed on edge devices, such as smartphones, IoT devices, and autonomous vehicles. This enables real-time processing, reduces latency, and improves privacy by keeping data on the device. Model compression and optimization techniques are crucial for enabling edge deployment.\n",
            "\n",
            "*   **Personalized AI Assistants are ubiquitous:** AI assistants powered by LLMs become deeply integrated into daily life. They anticipate user needs, proactively offer assistance, and adapt to individual preferences. These personalized assistants manage schedules, automate tasks, provide emotional support, and serve as companions. Ethical considerations regarding data privacy and algorithmic bias are paramount.\n",
            "\n",
            "*   **Self-Improving and Continually Learning LLMs:** LLMs exhibit enhanced self-improvement capabilities. They can analyze their own performance, identify areas for improvement, and autonomously refine their models using new data and experiences. Continual learning techniques enable LLMs to adapt to changing environments and evolving user needs without forgetting previous knowledge.\n",
            "\n",
            "*   **Advanced AI-Driven Content Creation:** LLMs revolutionize content creation across various industries. They can generate realistic and engaging text, images, audio, and video content for marketing, entertainment, and education. Concerns about copyright infringement and the potential for misuse of AI-generated content become increasingly important. Watermarking and provenance tracking technologies are implemented to address these issues.\n",
            "\n",
            "*   **LLMs for Scientific Discovery:** LLMs are used as powerful tools for scientific research. They can analyze vast datasets, identify patterns, generate hypotheses, and accelerate the pace of discovery in fields like drug discovery, materials science, and climate modeling. AI-driven scientific breakthroughs become increasingly common.\n",
            "\n",
            "*   **LLMs for Code Generation and Debugging:** LLMs become highly proficient at code generation and debugging. They can understand natural language instructions and translate them into working code in various programming languages. AI-powered code assistants automate repetitive coding tasks, identify bugs, and improve code quality. This accelerates software development and reduces the barrier to entry for aspiring programmers.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI LLMs Reporting Analyst\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mReview the context you got and expand each topic into a full section for a report. Make sure the report is detailed and contains any and all relevant information.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI LLMs Reporting Analyst\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "## Report on the Future of Large Language Models (LLMs) - 2025\n",
            "\n",
            "**Executive Summary:**\n",
            "\n",
            "This report outlines the projected advancements and transformative applications of Large Language Models (LLMs) by 2025. It details the shift towards domain-specific models, the integration of quantum computing, the rise of Explainable AI (XAI), the dominance of multimodal LLMs, edge deployment, the ubiquity of personalized AI assistants, self-improving LLMs, advanced AI-driven content creation, the use of LLMs for scientific discovery, and their proficiency in code generation and debugging. Ethical considerations and potential challenges are also addressed.\n",
            "\n",
            "**1. Widespread Domain-Specific LLMs:**\n",
            "\n",
            "By 2025, a significant paradigm shift will have occurred in the LLM landscape. General-purpose LLMs, while still relevant, will be largely superseded by highly specialized, domain-specific models. This specialization arises from the limitations of general models in achieving the accuracy and efficiency required in specific industries.\n",
            "\n",
            "*   **Medicine (Med-LLMs):** Med-LLMs will offer advanced diagnostic support, analyze patient data to create personalized treatment plans, and assist in drug discovery. These models will be trained on vast medical datasets, including research papers, clinical trials, and patient records. Imagine an LLM capable of analyzing medical images with higher accuracy than a human radiologist or predicting the likelihood of a patient responding positively to a specific drug based on their genetic makeup.\n",
            "*   **Law (Legal-LLMs):** Legal-LLMs will automate legal research, draft contracts, analyze case law, and predict litigation outcomes. They will streamline legal processes, reduce the time required for research, and minimize human error. For example, a Legal-LLM could analyze thousands of contracts in minutes, identifying potential risks and inconsistencies.\n",
            "*   **Finance (Fin-LLMs):** Fin-LLMs will provide sophisticated market analysis, risk assessment, fraud detection, and personalized investment advice. These models will process vast financial datasets, including market data, news articles, and economic indicators. They will identify market trends, predict stock prices, and detect fraudulent transactions with greater accuracy than traditional methods.\n",
            "*   **Education (Edu-LLMs):** Edu-LLMs will offer personalized learning experiences, automated grading, and adaptive tutoring. They will analyze student performance, identify learning gaps, and tailor educational content to individual needs. These models can provide instant feedback, personalized recommendations, and create engaging learning environments.\n",
            "\n",
            "The rise of domain-specific LLMs will lead to increased efficiency, accuracy, and innovation across various industries. However, it will also require specialized training datasets and expertise in each domain to ensure the models are reliable and effective.\n",
            "\n",
            "**2. Integration with Quantum Computing:**\n",
            "\n",
            "While full-scale quantum LLMs are unlikely by 2025, early integration of quantum computing principles will significantly enhance LLM capabilities. Hybrid classical-quantum approaches will be used to address specific computational bottlenecks.\n",
            "\n",
            "*   **Optimizing Model Parameters:** Quantum algorithms can be used to optimize the parameters of LLMs, leading to improved accuracy and efficiency. This involves finding the optimal configuration of weights and biases within the neural network.\n",
            "*   **Accelerating Training:** Quantum computing can speed up the training process of LLMs, reducing the time and resources required to develop these models. This is particularly beneficial for large models with billions of parameters.\n",
            "*   **Handling Complex Data Patterns:** Quantum algorithms can improve the ability of LLMs to handle complex data patterns, such as those found in financial markets or scientific research. This allows the models to identify subtle relationships and make more accurate predictions.\n",
            "*   **Improved Reasoning and Problem-Solving:** By leveraging quantum algorithms for specific tasks, LLMs will exhibit enhanced reasoning and problem-solving abilities. This will enable them to tackle more complex challenges and provide more insightful solutions.\n",
            "\n",
            "This early integration will pave the way for more advanced quantum LLMs in the future, unlocking even greater potential in AI.\n",
            "\n",
            "**3. Explainable AI (XAI) Becomes Mandatory:**\n",
            "\n",
            "Regulatory pressures and growing user demand will make Explainable AI (XAI) a mandatory requirement for LLMs, especially in critical applications. Users and regulators will demand transparency into the decision-making processes of these models.\n",
            "\n",
            "*   **Clear and Understandable Explanations:** LLMs will need to provide clear and understandable explanations for their decisions, outlining the factors that led to a particular outcome. This will involve developing techniques to trace the reasoning process within the complex neural networks.\n",
            "*   **Increased Trust and Accountability:** XAI will increase trust in LLMs by allowing users to understand how they arrive at their conclusions. This is particularly important in applications where decisions have significant consequences, such as in healthcare or finance. Furthermore, it enables accountability, as the reasoning behind decisions can be audited and scrutinized.\n",
            "*   **Advanced XAI Techniques:** Advanced XAI techniques will be developed to provide more detailed and nuanced explanations. This may involve visualizing the activation patterns within the neural network, identifying the key input features that influenced the decision, or generating counterfactual explanations that show how the outcome would change if certain factors were altered.\n",
            "*   **Mitigation of Bias:** XAI can help identify and mitigate bias in LLMs, ensuring that they make fair and equitable decisions. By understanding the reasoning process, developers can identify potential sources of bias and take steps to address them.\n",
            "\n",
            "The adoption of XAI will be crucial for the widespread acceptance and responsible use of LLMs.\n",
            "\n",
            "**4. Multimodal LLMs Dominate:**\n",
            "\n",
            "LLMs will evolve beyond text-based processing and become capable of seamlessly processing and generating information across multiple modalities, including text, images, audio, video, and sensor data.\n",
            "\n",
            "*   **Automated Video Editing:** Multimodal LLMs will be able to analyze video content, identify key scenes, and automatically edit videos for various purposes.\n",
            "*   **AI-Powered Music Composition:** These models will be able to compose original music based on user input or generate variations of existing songs.\n",
            "*   **Robots with Advanced Environmental Understanding:** Multimodal LLMs will enable robots to understand their environment through a combination of visual, auditory, and sensor data. This will allow them to navigate complex environments, interact with humans more naturally, and perform a wider range of tasks.\n",
            "*   **Cross-Modal Understanding:** LLMs will understand the relationships between different modalities. For example, they could generate a descriptive caption for an image or create a video based on a text script.\n",
            "\n",
            "The dominance of multimodal LLMs will unlock new possibilities in various fields, from entertainment and education to robotics and manufacturing.\n",
            "\n",
            "**5. Edge Deployment of LLMs:**\n",
            "\n",
            "LLMs will increasingly be deployed on edge devices, such as smartphones, IoT devices, and autonomous vehicles, moving beyond cloud-based infrastructure.\n",
            "\n",
            "*   **Real-Time Processing:** Edge deployment will enable real-time processing of data, reducing latency and improving responsiveness. This is crucial for applications that require immediate action, such as autonomous driving.\n",
            "*   **Reduced Latency:** Processing data on the device eliminates the need to send data to the cloud, reducing latency and improving user experience.\n",
            "*   **Improved Privacy:** Keeping data on the device improves privacy by preventing sensitive information from being transmitted over the internet.\n",
            "*   **Model Compression and Optimization:** Model compression and optimization techniques will be crucial for enabling edge deployment, as edge devices have limited computational resources and memory. This will involve reducing the size of the LLM without significantly sacrificing accuracy.\n",
            "\n",
            "Edge deployment will make LLMs more accessible, efficient, and secure, enabling a wider range of applications.\n",
            "\n",
            "**6. Personalized AI Assistants Are Ubiquitous:**\n",
            "\n",
            "AI assistants powered by LLMs will become deeply integrated into daily life, anticipating user needs, proactively offering assistance, and adapting to individual preferences.\n",
            "\n",
            "*   **Schedule Management:** AI assistants will manage schedules, book appointments, and send reminders.\n",
            "*   **Automated Tasks:** They will automate tasks such as paying bills, ordering groceries, and managing email.\n",
            "*   **Emotional Support:** AI assistants will provide emotional support, offering companionship and conversation.\n",
            "*   **Personalized Recommendations:** They will provide personalized recommendations for products, services, and entertainment based on user preferences.\n",
            "\n",
            "However, the ubiquity of personalized AI assistants raises ethical concerns regarding data privacy and algorithmic bias. Careful consideration must be given to how these assistants collect and use data, and steps must be taken to ensure that they are fair and equitable.\n",
            "\n",
            "**7. Self-Improving and Continually Learning LLMs:**\n",
            "\n",
            "LLMs will exhibit enhanced self-improvement capabilities, analyzing their own performance, identifying areas for improvement, and autonomously refining their models using new data and experiences.\n",
            "\n",
            "*   **Performance Analysis:** LLMs will be able to analyze their own performance, identifying areas where they are struggling.\n",
            "*   **Autonomous Refinement:** They will autonomously refine their models using new data and experiences, improving their accuracy and efficiency.\n",
            "*   **Continual Learning:** Continual learning techniques will enable LLMs to adapt to changing environments and evolving user needs without forgetting previous knowledge.\n",
            "\n",
            "This self-improvement capability will allow LLMs to continuously improve their performance and adapt to new challenges.\n",
            "\n",
            "**8. Advanced AI-Driven Content Creation:**\n",
            "\n",
            "LLMs will revolutionize content creation across various industries, generating realistic and engaging text, images, audio, and video content for marketing, entertainment, and education.\n",
            "\n",
            "*   **Automated Content Generation:** LLMs will be able to generate articles, blog posts, social media updates, and other forms of text content.\n",
            "*   **Image and Video Creation:** They will be able to create realistic images and videos for various purposes.\n",
            "*   **AI-Powered Marketing:** LLMs will be used to create personalized marketing campaigns, generate product descriptions, and create engaging ad copy.\n",
            "\n",
            "However, the potential for misuse of AI-generated content, such as the creation of fake news or deepfakes, becomes increasingly important. Copyright infringement is also a major concern. Watermarking and provenance tracking technologies will be implemented to address these issues.\n",
            "\n",
            "**9. LLMs for Scientific Discovery:**\n",
            "\n",
            "LLMs will be used as powerful tools for scientific research, analyzing vast datasets, identifying patterns, generating hypotheses, and accelerating the pace of discovery in fields like drug discovery, materials science, and climate modeling.\n",
            "\n",
            "*   **Drug Discovery:** LLMs will be used to analyze vast datasets of chemical compounds and biological data to identify potential drug candidates.\n",
            "*   **Materials Science:** They will be used to design new materials with specific properties.\n",
            "*   **Climate Modeling:** LLMs will be used to analyze climate data and predict the impact of climate change.\n",
            "\n",
            "AI-driven scientific breakthroughs will become increasingly common, transforming the way scientific research is conducted.\n",
            "\n",
            "**10. LLMs for Code Generation and Debugging:**\n",
            "\n",
            "LLMs will become highly proficient at code generation and debugging, understanding natural language instructions and translating them into working code in various programming languages.\n",
            "\n",
            "*   **Automated Code Generation:** LLMs will be able to generate code from natural language descriptions, automating repetitive coding tasks.\n",
            "*   **Bug Detection:** They will be able to identify bugs in code and suggest fixes.\n",
            "*   **Code Optimization:** LLMs will be able to optimize code for performance and efficiency.\n",
            "\n",
            "AI-powered code assistants will accelerate software development and reduce the barrier to entry for aspiring programmers.\n",
            "\n",
            "**Conclusion:**\n",
            "\n",
            "By 2025, LLMs will have a profound impact on various aspects of society, from healthcare and education to entertainment and scientific research. The advancements in domain specialization, quantum integration, explainability, multimodality, edge deployment, personalization, self-improvement, content creation, scientific discovery, and code generation will unlock new possibilities and transform industries. However, it is crucial to address the ethical considerations and potential challenges associated with these powerful technologies to ensure that they are used responsibly and for the benefit of all.\u001b[00m\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!crewai run\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nleMHEFsF7qK",
        "outputId": "a96289f0-e6bf-4c22-f83f-24d1639069de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running the Crew\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI LLMs Senior Data Researcher\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mConduct a thorough research about AI LLMs Make sure you find any interesting and relevant information given the current year is 2025.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI LLMs Senior Data Researcher\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "*   **Widespread Domain-Specific LLMs:** By 2025, general-purpose LLMs are largely complemented (and sometimes replaced) by highly specialized LLMs trained on massive datasets within specific industries. Examples include LLMs for medical diagnosis, legal research, financial modeling, and advanced manufacturing process optimization. These models offer significantly improved accuracy and efficiency within their domains.\n",
            "\n",
            "*   **Integration with Quantum Computing:** Preliminary integrations of LLMs with quantum computing architectures are emerging. While not yet fully realized for large-scale training, quantum-enhanced LLMs show promise for improved computational speed in specific tasks like complex pattern recognition and accelerated drug discovery. Hybrid classical-quantum architectures are common.\n",
            "\n",
            "*   **Advanced Explainable AI (XAI) Techniques:** Significant progress has been made in XAI for LLMs. New methods allow for more transparent and understandable explanations of LLM decision-making processes, addressing concerns about bias and lack of accountability. Techniques like attention visualization, concept activation vectors, and counterfactual explanations are commonly used for auditing and debugging.\n",
            "\n",
            "*   **Multimodal LLMs as Standard:** LLMs have evolved into truly multimodal models, seamlessly processing and generating text, images, audio, video, and sensor data. This enables applications like automated video editing with natural language instructions, real-time translation of speech and sign language, and AI-powered robotic systems that can understand and respond to complex environmental cues.\n",
            "\n",
            "*   **Federated Learning for Data Privacy:** Federated learning has become a crucial technique for training LLMs on decentralized data sources while preserving user privacy. LLMs are trained collaboratively across multiple devices or organizations without sharing the raw data, mitigating privacy risks and enabling access to larger and more diverse datasets.\n",
            "\n",
            "*   **Neuromorphic Computing for Energy Efficiency:** Neuromorphic computing architectures, inspired by the human brain, are gaining traction as a way to reduce the energy consumption of LLMs. These specialized hardware platforms offer significant improvements in energy efficiency compared to traditional CPU and GPU-based systems, making LLMs more sustainable and deployable on edge devices.\n",
            "\n",
            "*   **Personalized and Adaptive LLMs:** LLMs are increasingly personalized to individual users' needs and preferences. Adaptive learning algorithms allow LLMs to continuously learn from user interactions and tailor their responses accordingly, providing a more customized and engaging experience. Personal AI assistants powered by these adaptive LLMs are common.\n",
            "\n",
            "*   **Robustness Against Adversarial Attacks:** Enhanced defense mechanisms have been developed to protect LLMs from adversarial attacks. Techniques like adversarial training, input sanitization, and anomaly detection are used to improve the robustness of LLMs against malicious inputs designed to mislead or compromise the models.\n",
            "\n",
            "*   **Ethical Frameworks and Regulations:** Comprehensive ethical frameworks and regulations have been established to govern the development and deployment of LLMs. These guidelines address issues such as bias, fairness, transparency, accountability, and the potential misuse of LLMs for malicious purposes. Independent auditing and certification processes are in place to ensure compliance.\n",
            "\n",
            "*   **LLMs for Scientific Discovery:** LLMs are playing a major role in accelerating scientific discovery. They can analyze vast amounts of scientific literature, identify patterns and relationships, and generate hypotheses for further investigation. LLMs are used in fields such as drug discovery, materials science, and climate modeling to accelerate the pace of research and innovation.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI LLMs Reporting Analyst\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mReview the context you got and expand each topic into a full section for a report. Make sure the report is detailed and contains any and all relevant information.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI LLMs Reporting Analyst\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "# AI LLMs Reporting Analyst: Detailed Report on LLM Advancements by 2025\n",
            "\n",
            "## 1. Widespread Domain-Specific LLMs\n",
            "\n",
            "By 2025, the landscape of Large Language Models (LLMs) has undergone a significant transformation, moving away from a primarily general-purpose focus to a more specialized and domain-centric approach. While general-purpose LLMs still exist and provide a foundational level of functionality, they are now largely complemented, and in some cases, entirely replaced by highly specialized LLMs meticulously trained on massive, curated datasets within specific industries. This specialization addresses the limitations of general-purpose models in handling the nuanced complexities and technical jargon inherent in various sectors.\n",
            "\n",
            "**Key Characteristics:**\n",
            "\n",
            "*   **Enhanced Accuracy and Efficiency:** Domain-specific LLMs demonstrate substantially improved accuracy and efficiency compared to their general-purpose counterparts within their designated areas of expertise. This is primarily due to the concentrated training on relevant data, which allows the models to learn intricate patterns and relationships specific to the domain.\n",
            "*   **Examples Across Industries:**\n",
            "    *   **Medical Diagnosis:** LLMs trained on medical literature, patient records, and diagnostic imaging data assist physicians in making more accurate and timely diagnoses. These models can analyze symptoms, identify potential conditions, and suggest appropriate treatment plans, significantly improving patient outcomes.\n",
            "    *   **Legal Research:** LLMs trained on legal statutes, case law, and regulatory documents streamline legal research processes. Lawyers can quickly identify relevant precedents, analyze legal arguments, and draft legal documents with greater efficiency.\n",
            "    *   **Financial Modeling:** LLMs trained on financial data, market trends, and economic indicators assist financial analysts in building sophisticated financial models. These models can predict market movements, assess investment risks, and optimize portfolio strategies.\n",
            "    *   **Advanced Manufacturing Process Optimization:** LLMs trained on manufacturing data, sensor readings, and process parameters optimize manufacturing processes. These models can identify inefficiencies, predict equipment failures, and optimize production schedules, leading to improved productivity and reduced costs.\n",
            "*   **Reduced Hallucinations and Improved Contextual Understanding:** By focusing on a specific domain, these LLMs are less prone to generating nonsensical or irrelevant information (hallucinations) and possess a deeper understanding of the contextual nuances within that domain.\n",
            "\n",
            "**Impact:**\n",
            "\n",
            "The rise of domain-specific LLMs has profound implications across various industries. These models empower professionals with advanced tools for decision-making, problem-solving, and innovation, leading to increased productivity, improved efficiency, and better outcomes.\n",
            "\n",
            "## 2. Integration with Quantum Computing\n",
            "\n",
            "In the pursuit of enhanced computational capabilities, preliminary integrations of LLMs with quantum computing architectures are emerging by 2025. Although full-scale training of LLMs on quantum computers remains a challenge, the initial hybrid approaches demonstrate the potential of quantum computing to accelerate specific LLM tasks.\n",
            "\n",
            "**Key Aspects:**\n",
            "\n",
            "*   **Hybrid Classical-Quantum Architectures:** Given the current limitations of quantum computing, most integrations involve hybrid architectures where classical computers handle the bulk of the processing, while quantum computers are used for specific computationally intensive tasks.\n",
            "*   **Improved Computational Speed:** Quantum-enhanced LLMs have shown promise in accelerating tasks such as:\n",
            "    *   **Complex Pattern Recognition:** Quantum algorithms excel at identifying complex patterns in data, which can be leveraged to improve the ability of LLMs to recognize nuanced relationships and dependencies.\n",
            "    *   **Accelerated Drug Discovery:** Quantum simulations can be used to model molecular interactions and predict the properties of new drug candidates, significantly speeding up the drug discovery process.\n",
            "*   **Quantum-Enhanced Optimization:** Quantum annealing and other quantum optimization techniques can be used to optimize the parameters of LLMs, leading to improved accuracy and performance.\n",
            "\n",
            "**Challenges:**\n",
            "\n",
            "*   **Scalability:** Building quantum computers that are large and stable enough to train LLMs remains a significant technical challenge.\n",
            "*   **Algorithm Development:** Developing quantum algorithms that are specifically tailored for LLM tasks requires significant research and development efforts.\n",
            "*   **Cost:** Quantum computing resources are currently very expensive, which limits the widespread adoption of quantum-enhanced LLMs.\n",
            "\n",
            "**Future Outlook:**\n",
            "\n",
            "Despite these challenges, the integration of LLMs with quantum computing holds immense potential for revolutionizing the field of artificial intelligence. As quantum computing technology matures, we can expect to see more widespread adoption of quantum-enhanced LLMs, leading to breakthroughs in various domains.\n",
            "\n",
            "## 3. Advanced Explainable AI (XAI) Techniques\n",
            "\n",
            "Addressing the \"black box\" nature of traditional LLMs, significant strides have been made in the field of Explainable AI (XAI). By 2025, new methods are widely available that produce more transparent and understandable explanations of LLM decision-making processes. This is essential for building trust, mitigating bias, ensuring accountability, and complying with increasingly stringent regulations.\n",
            "\n",
            "**Commonly Used Techniques:**\n",
            "\n",
            "*   **Attention Visualization:** This technique allows users to visualize which parts of the input data the LLM is focusing on when making a prediction. By understanding which words or phrases the model is attending to, users can gain insights into the model's reasoning process.\n",
            "*   **Concept Activation Vectors (CAVs):** CAVs identify specific concepts that the LLM has learned and how these concepts influence the model's predictions. This helps users understand how the model is reasoning about the world and identify potential biases.\n",
            "*   **Counterfactual Explanations:** Counterfactual explanations provide examples of how the input data would need to be changed in order to produce a different prediction. This helps users understand the sensitivity of the model to different input features and identify potential vulnerabilities.\n",
            "*   **Layer-Wise Relevance Propagation (LRP):** LRP traces the decision-making process of the LLM back to the input features, highlighting the most relevant features for each prediction.\n",
            "\n",
            "**Benefits of XAI:**\n",
            "\n",
            "*   **Improved Trust:** Transparent explanations build trust in LLMs by allowing users to understand how the models arrive at their decisions.\n",
            "*   **Bias Detection and Mitigation:** XAI techniques can help identify and mitigate biases in LLMs, ensuring that the models are fair and equitable.\n",
            "*   **Increased Accountability:** By providing explanations for LLM decisions, XAI increases accountability and makes it easier to identify and correct errors.\n",
            "*   **Enhanced Debugging and Auditing:** XAI facilitates the debugging and auditing of LLMs, making it easier to identify and fix problems.\n",
            "\n",
            "**Impact:**\n",
            "\n",
            "The advancement of XAI techniques has been instrumental in fostering the responsible development and deployment of LLMs. These techniques empower users to understand, trust, and control LLMs, paving the way for broader adoption across various industries.\n",
            "\n",
            "## 4. Multimodal LLMs as Standard\n",
            "\n",
            "By 2025, LLMs have transcended the limitations of text-only processing and have evolved into truly multimodal models. These advanced models can seamlessly process and generate information across various modalities, including text, images, audio, video, and sensor data. This breakthrough has unlocked a plethora of new applications and capabilities.\n",
            "\n",
            "**Key Features:**\n",
            "\n",
            "*   **Unified Representation:** Multimodal LLMs learn a unified representation of information across different modalities, allowing them to understand and reason about the relationships between them.\n",
            "*   **Cross-Modal Understanding:** These models can understand the connections between different modalities, such as the relationship between an image and its corresponding text description.\n",
            "*   **Cross-Modal Generation:** Multimodal LLMs can generate content in one modality based on input from another modality, such as generating an image based on a text description.\n",
            "\n",
            "**Example Applications:**\n",
            "\n",
            "*   **Automated Video Editing:** Users can use natural language instructions to automatically edit videos, such as \"remove the background noise\" or \"add a fade-in effect.\"\n",
            "*   **Real-Time Translation of Speech and Sign Language:** Multimodal LLMs can translate speech into sign language in real-time, facilitating communication between deaf and hearing individuals.\n",
            "*   **AI-Powered Robotic Systems:** Robots can understand and respond to complex environmental cues, such as visual and auditory information, allowing them to perform tasks in dynamic and unstructured environments.\n",
            "*   **Image and Video Captioning:** Automatically generating descriptive captions for images and videos, enhancing accessibility and searchability.\n",
            "*   **Multimodal Question Answering:** Answering questions that require reasoning across multiple modalities, such as answering a question about an image based on its accompanying text description.\n",
            "\n",
            "**Impact:**\n",
            "\n",
            "The emergence of multimodal LLMs has revolutionized the field of artificial intelligence, enabling a new generation of applications that can understand and interact with the world in a more natural and intuitive way.\n",
            "\n",
            "## 5. Federated Learning for Data Privacy\n",
            "\n",
            "Federated learning has become an indispensable technique for training LLMs by 2025, especially in situations where data privacy is paramount. This approach enables collaborative training across multiple devices or organizations without requiring the direct sharing of raw data.\n",
            "\n",
            "**How Federated Learning Works:**\n",
            "\n",
            "1.  **Decentralized Training:** LLMs are trained on decentralized data sources, such as user devices or organizational servers.\n",
            "2.  **Local Model Training:** Each device or organization trains a local model on its own data.\n",
            "3.  **Model Aggregation:** The local models are aggregated to create a global model. This aggregation process typically involves averaging the model parameters or using more sophisticated techniques.\n",
            "4.  **Privacy Preservation:** Because the raw data is never shared, federated learning helps to preserve user privacy and mitigate the risks associated with data breaches.\n",
            "\n",
            "**Benefits of Federated Learning:**\n",
            "\n",
            "*   **Enhanced Privacy:** Federated learning protects user privacy by keeping data on local devices or within organizational boundaries.\n",
            "*   **Access to Larger Datasets:** Federated learning enables access to larger and more diverse datasets, leading to improved model accuracy and generalization.\n",
            "*   **Reduced Data Transfer Costs:** Federated learning reduces data transfer costs by eliminating the need to transfer large amounts of data to a central server.\n",
            "*   **Compliance with Data Privacy Regulations:** Federated learning helps organizations comply with data privacy regulations, such as GDPR and CCPA.\n",
            "\n",
            "**Applications:**\n",
            "\n",
            "*   **Personalized Healthcare:** Training LLMs on patient data without compromising patient privacy.\n",
            "*   **Financial Modeling:** Training LLMs on financial data without sharing sensitive financial information.\n",
            "*   **Smart City Applications:** Training LLMs on sensor data from smart city devices without compromising citizen privacy.\n",
            "\n",
            "**Impact:**\n",
            "\n",
            "Federated learning has emerged as a crucial technology for training LLMs in a privacy-preserving manner. This technique enables access to larger and more diverse datasets, leading to improved model accuracy and generalization while safeguarding user privacy.\n",
            "\n",
            "## 6. Neuromorphic Computing for Energy Efficiency\n",
            "\n",
            "Addressing the significant energy consumption challenges associated with training and deploying LLMs, neuromorphic computing architectures have gained considerable traction by 2025. Inspired by the human brain, these specialized hardware platforms offer substantial improvements in energy efficiency compared to traditional CPU and GPU-based systems.\n",
            "\n",
            "**Key Principles of Neuromorphic Computing:**\n",
            "\n",
            "*   **Spiking Neural Networks (SNNs):** Neuromorphic chips often utilize SNNs, which mimic the way neurons in the brain communicate using spikes. This event-driven approach can significantly reduce energy consumption.\n",
            "*   **In-Memory Computing:** Neuromorphic architectures often integrate memory and processing units on the same chip, reducing the need to move data between different components.\n",
            "*   **Parallel Processing:** Neuromorphic chips are designed for highly parallel processing, which allows them to perform complex computations with high efficiency.\n",
            "\n",
            "**Benefits of Neuromorphic Computing:**\n",
            "\n",
            "*   **Reduced Energy Consumption:** Neuromorphic computing can significantly reduce the energy consumption of LLMs, making them more sustainable and environmentally friendly.\n",
            "*   **Improved Performance:** Neuromorphic architectures can offer improved performance for certain LLM tasks, such as pattern recognition and anomaly detection.\n",
            "*   **Edge Deployment:** The energy efficiency of neuromorphic computing makes it possible to deploy LLMs on edge devices, such as smartphones and wearable devices.\n",
            "\n",
            "**Applications:**\n",
            "\n",
            "*   **Edge AI:** Deploying LLMs on edge devices for real-time processing of data without relying on cloud connectivity.\n",
            "*   **Robotics:** Using neuromorphic chips to control robots with greater energy efficiency.\n",
            "*   **Biomedical Applications:** Using neuromorphic computing to process biomedical data, such as EEG signals and medical images.\n",
            "\n",
            "**Impact:**\n",
            "\n",
            "Neuromorphic computing is revolutionizing the field of artificial intelligence by providing a more energy-efficient and sustainable platform for training and deploying LLMs. This technology is enabling a new generation of AI applications that can be deployed on edge devices and operate with minimal power consumption.\n",
            "\n",
            "## 7. Personalized and Adaptive LLMs\n",
            "\n",
            "LLMs are increasingly tailored to individual users' needs and preferences by 2025. Adaptive learning algorithms enable these models to continuously learn from user interactions and dynamically adjust their responses.\n",
            "\n",
            "**Key Features:**\n",
            "\n",
            "*   **User Profiling:** LLMs create user profiles based on their interactions, preferences, and historical data.\n",
            "*   **Adaptive Learning:** LLMs use adaptive learning algorithms to continuously learn from user interactions and tailor their responses accordingly.\n",
            "*   **Personalized Recommendations:** LLMs provide personalized recommendations for products, services, and content based on user preferences.\n",
            "*   **Contextual Understanding:** LLMs understand the context of user interactions and provide more relevant and helpful responses.\n",
            "\n",
            "**Applications:**\n",
            "\n",
            "*   **Personal AI Assistants:** AI assistants powered by adaptive LLMs provide a customized and engaging experience.\n",
            "*   **Personalized Education:** LLMs tailor educational content to individual student needs and learning styles.\n",
            "*   **Personalized Healthcare:** LLMs provide personalized healthcare recommendations and support based on individual patient needs.\n",
            "*   **Personalized Marketing:** LLMs personalize marketing messages and offers based on individual customer preferences.\n",
            "\n",
            "**Impact:**\n",
            "\n",
            "The personalization and adaptation of LLMs have significantly improved user engagement and satisfaction. These models provide a more customized and relevant experience, leading to increased productivity and better outcomes.\n",
            "\n",
            "## 8. Robustness Against Adversarial Attacks\n",
            "\n",
            "Ensuring the security and reliability of LLMs, enhanced defense mechanisms have been developed by 2025 to protect against adversarial attacks. These attacks involve malicious inputs designed to mislead or compromise the models.\n",
            "\n",
            "**Common Defense Techniques:**\n",
            "\n",
            "*   **Adversarial Training:** LLMs are trained on adversarial examples, which are inputs that have been slightly perturbed to cause the model to make a mistake. This helps the model to become more robust to adversarial attacks.\n",
            "*   **Input Sanitization:** Input sanitization involves filtering out or modifying potentially malicious inputs before they are fed into the LLM.\n",
            "*   **Anomaly Detection:** Anomaly detection techniques are used to identify unusual or suspicious inputs that may be indicative of an adversarial attack.\n",
            "*   **Defensive Distillation:** This technique involves training a smaller, more robust model to mimic the behavior of a larger, more vulnerable model.\n",
            "\n",
            "**Impact:**\n",
            "\n",
            "These defense mechanisms have significantly improved the robustness of LLMs against adversarial attacks, making them more secure and reliable for a wide range of applications.\n",
            "\n",
            "## 9. Ethical Frameworks and Regulations\n",
            "\n",
            "Recognizing the potential risks associated with LLMs, comprehensive ethical frameworks and regulations have been established by 2025 to govern their development and deployment. These guidelines address critical issues such as bias, fairness, transparency, accountability, and the potential for misuse.\n",
            "\n",
            "**Key Components:**\n",
            "\n",
            "*   **Bias Mitigation:** Frameworks emphasize the importance of identifying and mitigating biases in LLMs to ensure that the models are fair and equitable.\n",
            "*   **Transparency and Explainability:** Regulations promote the development of transparent and explainable LLMs, making it easier to understand how the models arrive at their decisions.\n",
            "*   **Accountability:** Frameworks establish clear lines of accountability for the development and deployment of LLMs, ensuring that individuals and organizations are responsible for the actions of their models.\n",
            "*   **Misuse Prevention:** Regulations address the potential misuse of LLMs for malicious purposes, such as generating fake news or spreading disinformation.\n",
            "*   **Independent Auditing and Certification:** Independent auditing and certification processes are in place to ensure compliance with ethical guidelines and regulations.\n",
            "\n",
            "**Impact:**\n",
            "\n",
            "These ethical frameworks and regulations have fostered the responsible development and deployment of LLMs, mitigating potential risks and promoting the beneficial use of this powerful technology.\n",
            "\n",
            "## 10. LLMs for Scientific Discovery\n",
            "\n",
            "LLMs play a significant role in accelerating scientific discovery by 2025. They are able to analyze vast amounts of scientific literature, identify patterns and relationships, and generate hypotheses for further investigation.\n",
            "\n",
            "**Applications in Scientific Research:**\n",
            "\n",
            "*   **Drug Discovery:** LLMs analyze vast amounts of scientific literature and experimental data to identify potential drug candidates and predict their efficacy.\n",
            "*   **Materials Science:** LLMs analyze the properties of different materials and predict the behavior of new materials.\n",
            "*   **Climate Modeling:** LLMs analyze climate data and predict future climate trends.\n",
            "*   **Hypothesis Generation:** LLMs generate hypotheses for further investigation based on patterns and relationships identified in scientific literature.\n",
            "\n",
            "**Impact:**\n",
            "\n",
            "LLMs are accelerating the pace of scientific research and innovation, leading to breakthroughs in various fields. They enable scientists to analyze vast amounts of data, identify patterns, and generate hypotheses more efficiently than ever before.\u001b[00m\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}